diff --git a/README.md b/README.md
index 5605c5a..ef4a2f1 100644
--- a/README.md
+++ b/README.md
@@ -3,7 +3,7 @@
 ```
 pip install torch numpy transformers datasets tiktoken wandb tqdm
 wandb login xxxx # xxxx = auth token, find it at wandb.ai/authorize Otherwise, send wandb_logging to False
-python data/lichess_hf_dataset/prepare.py
+python data/lichess_hf_dataset/prepare_elo_bins.py
 python train.py config/train_shakespeare_char.py
 python sample.py --out_dir=out-shakespeare-char
 ```
diff --git a/config/train_shakespeare_char.py b/config/train_shakespeare_char.py
index 096989a..8c81f73 100644
--- a/config/train_shakespeare_char.py
+++ b/config/train_shakespeare_char.py
@@ -31,7 +31,7 @@ min_lr = 3e-5 # learning_rate / 10 usually
 beta2 = 0.95 # make a bit bigger because number of tokens per iter is small
 
 warmup_iters = 10000 # not super necessary potentially
-compile = True
+compile = False
 
 # on macbook also add
 # device = 'cpu'  # run on cpu only
diff --git a/train.py b/train.py
index c8c9d81..90aec5d 100644
--- a/train.py
+++ b/train.py
@@ -77,6 +77,10 @@ config_keys = [k for k,v in globals().items() if not k.startswith('_') and isins
 exec(open('configurator.py').read()) # overrides from command line or config file
 config = {k: globals()[k] for k in config_keys} # will be useful for logging
 # -----------------------------------------------------------------------------
+low_elo = 600
+high_elo = 1100
+
+
 
 # various inits, derived attributes, I/O setup
 ddp = int(os.environ.get('RANK', -1)) != -1 # is this a ddp run?
@@ -113,8 +117,10 @@ ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=
 
 # poor man's data loader
 data_dir = os.path.join('data', dataset)
-train_data = np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint8, mode='r')
-val_data = np.memmap(os.path.join(data_dir, 'val.bin'), dtype=np.uint8, mode='r')
+train_data = np.memmap(os.path.join(data_dir, f'train.bin'), dtype=np.uint8, mode='r')
+val_data = np.memmap(os.path.join(data_dir, f'val.bin'), dtype=np.uint8, mode='r')
+# train_data = np.memmap(os.path.join(data_dir, f'train_{low_elo}_{high_elo}.bin'), dtype=np.uint8, mode='r')
+# val_data = np.memmap(os.path.join(data_dir, f'val_{low_elo}_{high_elo}.bin'), dtype=np.uint8, mode='r')
 def get_batch(split):
     data = train_data if split == 'train' else val_data
     # ix = torch.randint(len(data) - block_size, (batch_size,))
